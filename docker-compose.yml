version: '3.8'  
services:
  # spark stack
  spark-master:
    image: bitnami/spark:3.4.0
    user: root # Run container as root container: https://docs.bitnami.com/tutorials/work-with-non-root-containers/
    hostname: spark-master
    ports:
        - 8081:8080
        - 7077:7077
        - 4040:4040
    environment:
        - SPARK_MODE=master
        - SPARK_RPC_AUTHENTICATION_ENABLED=no
        - SPARK_RPC_ENCRYPTION_ENABLED=no
        - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
        - SPARK_SSL_ENABLED=no
    volumes:
        - ./src/spark/app:/opt/src/spark/app # Scripts (same path in airflow and spark)
        - ./src/spark/resources:/opt/src/spark/resources # Resources (same path in airflow and spark)

  spark-worker:
    image: bitnami/spark:3.4.0
    user: root
    environment:
        - SPARK_MODE=worker
        - SPARK_MASTER_URL=spark://spark-master:7077
        - SPARK_WORKER_MEMORY=3G
        - SPARK_WORKER_CORES=12
        - SPARK_RPC_AUTHENTICATION_ENABLED=no
        - SPARK_RPC_ENCRYPTION_ENABLED=no
        - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
        - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    volumes:
        - ./src/spark/app:/opt/spark/app # Scripts (same path in airflow and spark)
        - ./src/spark/resources:/opt/spark/resources # Resources (same path in airflow and spark)
#TODO: Add user permissions
  spark-history-server:
    image: bitnami/spark:3.4.0
    user: root
    ports:
      - 18080:18080
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/spark/resources/logs
    volumes:
      - ./src/spark/resources/logs:/opt/spark/resources/logs
    command: >
      bash -c "/opt/bitnami/spark/sbin/start-history-server.sh"


  # python dev enviroment
  python:
    image: python3.10.6
    build:
      context: .
      dockerfile: ./Dockerfile
    ports:
      - 8888:8888
    volumes:
      - .:/opt/ufo-lakehouse