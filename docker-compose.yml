version: '3.8'
services:
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    hostname: spark-master
    user: root
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_CONF_DIR=/opt/bitnami/spark/conf
      - SPARK_EVENTLOG_ENABLED=true
      - SPARK_EVENTLOG_DIR=/opt/bitnami/spark/logs
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=file:/opt/bitnami/spark/logs
      - SPARK_SQL_EXTENSIONS=io.delta.sql.DeltaSparkSessionExtension
      - SPARK_SQL_CATALOG_IMPLEMENTATION=io.delta.sql.DeltaCatalog
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - ./spark-warehouse:/opt/bitnami/spark/data
      - ./src/spark/logs:/opt/bitnami/spark/logs
      - ./src/spark/conf:/opt/spark_reqs/conf
      - ./src/spark/jars:/opt/spark_reqs/jars
    command: >
      bash -c "cp -p /opt/spark_reqs/conf/spark-defaults.conf /opt/bitnami/spark/conf && cp -p /opt/spark_reqs/jars/delta-core_2.12-2.4.0.jar /opt/bitnami/spark/jars && /opt/bitnami/spark/sbin/start-master.sh"

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    hostname: spark-worker
    user: root
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_CONF_DIR=/opt/bitnami/spark/conf
      - SPARK_EVENTLOG_ENABLED=true
      - SPARK_EVENTLOG_DIR=/opt/bitnami/spark/logs
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=file:/opt/bitnami/spark/logs
      - SPARK_SQL_EXTENSIONS=io.delta.sql.DeltaSparkSessionExtension
      - SPARK_SQL_CATALOG_IMPLEMENTATION=io.delta.sql.DeltaCatalog
      - SPARK_DRIVER_MEMORY=4g
      - SPARK_EXECUTOR_MEMORY=4g
      - SPARK_DRIVER_CORES=3
      - SPARK_EXECUTOR_CORES=10
    ports:
      - 4040:4040
    volumes:
      - ./spark-warehouse:/opt/bitnami/spark/data
      - ./src/spark/logs:/opt/bitnami/spark/logs
      - ./src/spark/conf:/opt/spark_reqs/conf
      - ./src/spark/jars:/opt/spark_reqs/jars
    command: >
      bash -c "cp -p /opt/spark_reqs/conf/spark-defaults.conf /opt/bitnami/spark/conf && cp -p /opt/spark_reqs/jars/delta-core_2.12-2.4.0.jar /opt/bitnami/spark/jars && /opt/bitnami/spark/sbin/start-worker.sh spark://spark-master:7077"

  spark-history-server:
    image: bitnami/spark:latest
    container_name: spark-history-server
    hostname: spark-history-server
    user: root
    depends_on:
      - spark-master
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=file:/opt/bitnami/spark/logs
      - SPARK_CONF_DIR=/opt/bitnami/spark/conf
    ports:
      - 18080:18080
    volumes:
      - ./spark-warehouse:/opt/bitnami/spark/data
      - ./src/spark/logs:/opt/bitnami/spark/logs
      - ./src/spark/conf:/opt/spark_reqs/conf
      - ./src/spark/jars:/opt/spark_reqs/jars
    command: >
      bash -c "cp /opt/spark_reqs/conf/spark-defaults.conf /opt/bitnami/spark/conf && cp /opt/spark_reqs/jars/delta-core_2.12-2.4.0.jar /opt/bitnami/spark/jars && /opt/bitnami/spark/sbin/start-history-server.sh"

  # python dev enviroment
  python:
    image: python3.10.6
    container_name: python3.10.6
    hostname: python3.10.6
    build:
      context: .
      dockerfile: ./Dockerfile
    ports:
      - 8888:8888
    volumes:
      - .:/opt/ufo-lakehouse
