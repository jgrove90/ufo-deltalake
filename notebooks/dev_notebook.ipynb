{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgrove/.local/lib/python3.10/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spark.ufo as ufo\n",
    "import utils.spark_utils as su\n",
    "from utils.utils import get_moon_phase\n",
    "from utils.address_cleaning import clean_address\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/06/07 19:05:27 WARN Utils: Your hostname, helion resolves to a loopback address: 127.0.1.1; using 172.21.218.81 instead (on interface eth0)\n",
      "23/06/07 19:05:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/jgrove/.local/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jgrove/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jgrove/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-15009b83-d3cf-4052-b928-6acbb23df0eb;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 85ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-15009b83-d3cf-4052-b928-6acbb23df0eb\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
      "23/06/07 19:05:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/07 19:05:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# spark://172.18.0.4:7077\n",
    "spark = su.spark_session()\n",
    "#spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"MyApp\") \\\n",
    "#     .master(\"spark://localhost:7077\") \\\n",
    "#     .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----+-------+--------+------------------+--------------------+-------+------+\n",
      "|     DateTime|          City|State|Country|   Shape|          Duration|             Summary| Posted|Images|\n",
      "+-------------+--------------+-----+-------+--------+------------------+--------------------+-------+------+\n",
      "|5/31/22 23:28|      Old Fort|   TN|    USA|   Light|       5-6 seconds|Light that appear...|6/22/22|   Yes|\n",
      "|5/31/22 23:00|    Long Beach|   CA|    USA|Fireball|       1.5 minutes|Large Hovering Fi...|6/22/22|  null|\n",
      "|5/31/22 22:34|Lake Hopatcong|   NJ|    USA|   Light|                .5|Red light gets su...|6/22/22|  null|\n",
      "|5/31/22 22:24|Lake Hopatcong|   NJ|    USA|   Light|10:24:47- 10:24:48|Red light gets su...|6/22/22|  null|\n",
      "|5/31/22 22:00|        Medina|   OH|    USA|    Star|   approx 1 minute|looked like A ver...|6/22/22|  null|\n",
      "+-------------+--------------+-----+-------+--------+------------------+--------------------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#spark.sql(\"REFRESH TABLE bronze\")\n",
    "# spark.catalog.refreshTable(r\"`./spark-warehouse/ufo/bronze`\")\n",
    "#spark.sql(\"REFRESH TABLE `'/spark-warehouse/ufo/bronze'`\")\n",
    "df = spark.read.format(\"delta\").load(r\"../spark-warehouse/ufo/bronze\").limit(5)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+-----------+--------------+--------+---------+--------+------------------+--------------------+------+----------+----+-----+---------+----+----+--------------+\n",
      "| id|            city|      state|       country|latitude|longitude|   shape|          duration|             summary|images|      date|year|month|dayOfWeek|week|hour|moonPhaseAngle|\n",
      "+---+----------------+-----------+--------------+--------+---------+--------+------------------+--------------------+------+----------+----+-----+---------+----+----+--------------+\n",
      "|  0|      Long Beach| California| United States|  33.769| -118.192|Fireball|       1.5 minutes|Large Hovering Fi...|  null|2022-05-31|2022|    5|  Tuesday|  22|  23|           0.0|\n",
      "|  1|            None|       Ohio| United States|    41.1|  -81.938|    Star|   approx 1 minute|looked like A ver...|  null|2022-05-31|2022|    5|  Tuesday|  22|  22|           0.0|\n",
      "|  2|Roxbury Township| New Jersey| United States|    null|     null|   Light|10:24:47- 10:24:48|Red light gets su...|  null|2022-05-31|2022|    5|  Tuesday|  22|  22|           0.0|\n",
      "|  3|      Manchester|  Tennessee| United States|  35.484|  -86.105|   Light|       5-6 seconds|Light that appear...|   Yes|2022-05-31|2022|    5|  Tuesday|  22|  23|           0.0|\n",
      "|  4|Roxbury Township| New Jersey| United States|  40.904|  -74.665|   Light|                .5|Red light gets su...|  null|2022-05-31|2022|    5|  Tuesday|  22|  22|           0.0|\n",
      "+---+----------------+-----------+--------------+--------+---------+--------+------------------+--------------------+------+----------+----+-----+---------+----+----+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Register the get_moon_phase() function as a UDF.\n",
    "get_moon_phase_udf = udf(get_moon_phase)\n",
    "clean_address_udf = udf(clean_address)\n",
    "\n",
    "\n",
    "df = (\n",
    "    df.filter(df.Country == \"USA\")\n",
    "    .withColumn(\"timestamp\", to_timestamp(\"DateTime\", \"MM/dd/yy HH:mm\"))\n",
    "    .withColumn(\"temp_address\", concat_ws(\", \", df.City, df.State, df.Country))\n",
    "    .withColumn(\"address\", clean_address_udf(\"temp_address\"))\n",
    "    .withColumn(\"city\", split(\"address\", \",\").getItem(0))\n",
    "    .withColumn(\"state\", split(\"address\", \",\").getItem(1))\n",
    "    .withColumn(\"country\", split(\"address\", \",\").getItem(2))\n",
    "    .withColumn(\"latitude\", round(split(\"address\", \",\").getItem(3).cast(\"double\"), 3))\n",
    "    .withColumn(\"longitude\", round(split(\"address\", \",\").getItem(4).cast(\"double\"), 3))\n",
    "    .withColumn(\"date\", to_date(\"timestamp\"))\n",
    "    .withColumn(\"year\", year(\"date\"))\n",
    "    .withColumn(\"month\", month(\"date\"))\n",
    "    .withColumn(\"dayOfWeek\", date_format(\"date\", \"EEEE\"))\n",
    "    .withColumn(\"week\", weekofyear(\"date\"))\n",
    "    .withColumn(\"hour\", hour(\"timestamp\"))\n",
    "    .withColumn(\"moonPhaseAngle\", get_moon_phase_udf(\"date\").cast(\"double\"))\n",
    "    .withColumnRenamed(\"Images\", \"images\")\n",
    "    .drop(\"DateTime\", \"Posted\", \"timestamp\", \"temp_address\")\n",
    "    #.na.drop(subset=[\"city\", \"state\", \"latitude\", \"longitude\"])\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"id\", monotonically_increasing_id())\n",
    "    .select(\n",
    "        \"id\",\n",
    "        \"city\",\n",
    "        \"state\",\n",
    "        \"country\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"shape\",\n",
    "        \"duration\",\n",
    "        \"summary\",\n",
    "        \"images\",\n",
    "        \"date\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"dayOfWeek\",\n",
    "        \"week\",\n",
    "        \"hour\",\n",
    "        \"moonPhaseAngle\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- shape: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- images: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- dayofweek: string (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- moonphase: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------------+---------+\n",
      "| id|                city|          state|  country|\n",
      "+---+--------------------+---------------+---------+\n",
      "|  0|        Ocean Shores|New South Wales|Australia|\n",
      "|  1|Cayo Costa state ...|             FL|      USA|\n",
      "|  2|         Southampton|             MA|      USA|\n",
      "|  3|ST BRUNO DE MONTA...|         Quebec|   Canada|\n",
      "|  4|             Bedford|             VA|      USA|\n",
      "|  5|          Scottsdale|             AZ|      USA|\n",
      "|  6|           St. Louis|             MO|      USA|\n",
      "|  7|            St louis|             MO|      USA|\n",
      "|  8|             WICHITA|             KS|      USA|\n",
      "|  9|           Skowhegan|             ME|      USA|\n",
      "| 10|                null|             CA|      USA|\n",
      "| 11|            Humboldt|             TN|      USA|\n",
      "| 12|              Encino|             CA|      USA|\n",
      "| 13|           Texarkana|             AR|      USA|\n",
      "| 14|              Vernon|             TX|      USA|\n",
      "| 15|            Paradise|             UT|      USA|\n",
      "| 16|           Lancaster|             PA|      USA|\n",
      "| 17|             Lawtell|             LA|      USA|\n",
      "| 18|               Cairo|             NY|      USA|\n",
      "| 19|               Longs|             SC|      USA|\n",
      "+---+--------------------+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+---------+--------------------+--------------------+\n",
      "| id|    shape|             summary|            duration|\n",
      "+---+---------+--------------------+--------------------+\n",
      "|  0| Triangle|Large triangle no...|          20 secinds|\n",
      "|  1|Rectangle|watched one row o...|       One hour plus|\n",
      "|  2|    Light|Light was station...|         3-5 minutes|\n",
      "|  3| Changing|we saw an object ...|              1 hour|\n",
      "|  4|     Cube|Fast moving orbs ...|               2 min|\n",
      "|  5|  Unknown|It looked segment...|          20 minutes|\n",
      "|  6|  Unknown|Saw 3 objects in ...|           5 minutes|\n",
      "|  7|  Unknown|Saw 3 objects in ...|           5 minutes|\n",
      "|  8|    Flash|High attitude lar...|           2 seconds|\n",
      "|  9| Triangle|Built a high Tesl...|About 1 min (1/2 ...|\n",
      "| 10|      Orb|3 orbs of light, ...|          10 minutes|\n",
      "| 11|    Light|Saw several jets ...|         1-3 minutes|\n",
      "| 12| Changing|Witnessed surreal...|          57 seconds|\n",
      "| 13|   Circle|The pilot of BYA5...|             Unknown|\n",
      "| 14| Triangle|Object traveling ...|       10-20 seconds|\n",
      "| 15|      Orb|Sighted a strange...|  Approx. 5+ minutes|\n",
      "| 16|    Flash|Multi flashing ob...|             10 mins|\n",
      "| 17|    Light|2 extremely low \"...|     Approx 2-3 mins|\n",
      "| 18|  Diamond|Not a craft and n...|         58 minutes|\n",
      "| 19|    Light|Balls of light th...|    On going (daily)|\n",
      "+---+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+----+-----+---------+----+----+\n",
      "|      date|year|month|dayofweek|week|hour|\n",
      "+----------+----+-----+---------+----+----+\n",
      "|2023-04-08|2023|    4| Saturday|  14|  18|\n",
      "|2023-04-08|2023|    4| Saturday|  14|   9|\n",
      "|2023-04-08|2023|    4| Saturday|  14|   5|\n",
      "|2023-04-07|2023|    4|   Friday|  14|  22|\n",
      "|2023-04-07|2023|    4|   Friday|  14|  21|\n",
      "|2023-04-07|2023|    4|   Friday|  14|  18|\n",
      "|2023-04-07|2023|    4|   Friday|  14|   8|\n",
      "|2023-04-07|2023|    4|   Friday|  14|   8|\n",
      "|2023-04-07|2023|    4|   Friday|  14|   6|\n",
      "|2023-04-07|2023|    4|   Friday|  14|   2|\n",
      "|2023-04-07|2023|    4|   Friday|  14|   2|\n",
      "|2023-04-19|2023|    4|Wednesday|  16|   7|\n",
      "|2023-04-19|2023|    4|Wednesday|  16|   4|\n",
      "|2023-04-19|2023|    4|Wednesday|  16|   0|\n",
      "|2023-04-18|2023|    4|  Tuesday|  16|  23|\n",
      "|2023-04-18|2023|    4|  Tuesday|  16|  23|\n",
      "|2023-04-18|2023|    4|  Tuesday|  16|  22|\n",
      "|2023-04-18|2023|    4|  Tuesday|  16|  21|\n",
      "|2023-04-18|2023|    4|  Tuesday|  16|  21|\n",
      "|2023-04-18|2023|    4|  Tuesday|  16|  21|\n",
      "+----------+----+-----+---------+----+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+---------+\n",
      "| id|moonphase|\n",
      "+---+---------+\n",
      "|  0|     0.96|\n",
      "|  1|     0.96|\n",
      "|  2|     0.96|\n",
      "|  3|     0.99|\n",
      "|  4|     0.99|\n",
      "|  5|     0.99|\n",
      "|  6|     0.99|\n",
      "|  7|     0.99|\n",
      "|  8|     0.99|\n",
      "|  9|     0.99|\n",
      "| 10|     0.99|\n",
      "| 11|     0.02|\n",
      "| 12|     0.02|\n",
      "| 13|     0.02|\n",
      "| 14|     0.06|\n",
      "| 15|     0.06|\n",
      "| 16|     0.06|\n",
      "| 17|     0.06|\n",
      "| 18|     0.06|\n",
      "| 19|     0.06|\n",
      "+---+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_location = (df.select(\"id\", \"city\", \"state\", \"country\"))\n",
    "\n",
    "df_ufo = (df.select(\"id\", \"shape\", \"summary\", \"duration\"))\n",
    "\n",
    "df_date = (df.select(\"date\", \"year\", \"month\", \"dayofweek\", \"week\", \"hour\"))\n",
    "\n",
    "df_astronomy = (df.select(\"id\", \"moonphase\"))\n",
    "\n",
    "\n",
    "df_location.show()\n",
    "df_ufo.show()\n",
    "df_date.show()\n",
    "df_astronomy.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
